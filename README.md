# Adobe-India-Hackathon---2025
# ğŸ¤– Adobe Hackathon â€“ Round 1B: Persona-Driven Document Intelligence

## ğŸ§© Objective

Design an intelligent system that extracts and ranks the most relevant sections and subsections from a collection of PDFs, based on:
- A defined Persona
- A specific Job-to-be-done

---

## ğŸ§  Problem Statement

Given:
- 3â€“10 PDFs from any domain
- A persona (e.g., Student, Researcher, Analyst)
- A concrete task related to the persona

Your system must:
1. Understand the personaâ€™s goal
2. Identify and rank relevant sections across all documents
3. Provide meaningful subsection-level insights

---

## ğŸ›  Approach

Our pipeline consists of the following steps:

### 1. ğŸ“¥ Input Parsing
- Accepts multiple PDFs and a JSON description of the persona and job-to-be-done
- Extracts raw text and page-wise structure

### 2. ğŸ§  Semantic Understanding
- Embeds persona and job definition using transformer-based models (e.g., DistilBERT/Sentence-BERT)
- Embeds each section from all PDFs
- Computes cosine similarity between job-to-be-done and document sections

### 3. ğŸ” Section Selection
- Sections are ranked by similarity scores
- Top N sections are selected with importance_rank

### 4. ğŸª„ Subsection Extraction
- Each top section is further analyzed for key insights using:
  - Sentence scoring
  - Text summarization (if applicable)

---

## ğŸ“š Libraries & Models Used

- PyMuPDF or pdfplumber â€“ PDF parsing
- sentence-transformers â€“ Semantic similarity
- nltk, spacy â€“ NLP preprocessing
- Optional: lightweight transformer models (â‰¤ 1GB)

âœ… Entire pipeline runs offline  
âœ… Fully CPU-compatible (no GPU required)  
âœ… Model size kept below 1GB

---

## ğŸ“¦ Output Format

Example JSON output:

### 1. Metadata
```json
{
  "documents": ["doc1.pdf", "doc2.pdf"],
  "persona": "Investment Analyst",
  "job_to_be_done": "Analyze R&D spending trends",
  "timestamp": "2025-07-28T14:33:00Z"
}